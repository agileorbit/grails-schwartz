[[tutorials]]
== Tutorials

[[basicTutorial]]
=== Basic Tutorial

==== Create your Grails application.

....
$ grails create-app schwartztest
$ cd schwartztest
....

==== "`Install`" the plugin by adding it to build.gradle

Add a dependency for the plugin by adding it to the `dependencies` block in build.gradle:

[source,groovy]
[subs="attributes"]
----
buildscript {
   repositories {
      ...
   }
   dependencies {
      classpath "org.grails:grails-gradle-plugin:$grailsVersion"
      ...
      classpath 'com.agileorbit:schwartz:{project-version}'
   }
}

dependencies {
   ...
   compile 'com.agileorbit:schwartz:{project-version}'
   ...
}
----

==== Create a job that's a transactional service

Next we'll create some job classes. First, we'll create a job that's a transactional service:

....
$ grails create-job Skroob
....

Note that even though Schwartz jobs aren't Grails artifacts and there is no enforced naming convention, the <<create-job>> script adds the "`Job`" suffix for you if the specified name doesn't end in "`Job`", and "`JobService`" when creating jobs in `grails-app/services`, but this is not a requirement (other than the general Grails requirement that service names end in "`Service`"), just a convenience.

The script will create the class under `grails-app/services` in the specified package, or in the default package if none is specified (as in this case), with commented-out example triggers that aren't shown here:

[source,groovy]
----
package schwartztest

import com.agileorbit.schwartz.SchwartzJob
import grails.gorm.transactions.Transactional
import groovy.transform.CompileStatic
import groovy.util.logging.Slf4j
import org.quartz.JobExecutionContext
import org.quartz.JobExecutionException

@CompileStatic
@Slf4j
class SkroobJobService implements SchwartzJob {

   @Transactional
   void execute(JobExecutionContext context) throws JobExecutionException {
   }

   void buildTriggers() {
   }
}
----

Edit the file to add a simple trigger that fires every second, and a println in the `execute` method to verify that it's working:

[source,groovy]
----
package schwartztest

import com.agileorbit.schwartz.SchwartzJob
import grails.gorm.transactions.Transactional
import groovy.transform.CompileStatic
import groovy.util.logging.Slf4j
import org.quartz.JobExecutionContext
import org.quartz.JobExecutionException

@CompileStatic
@Slf4j
class SkroobJobService implements SchwartzJob {

   @Transactional
   void execute(JobExecutionContext context) throws JobExecutionException {
      println "$context.trigger.key/$context.jobDetail.key at ${new Date()}"
   }

   void buildTriggers() {
      triggers << factory('Skroob_EverySecond').intervalInSeconds(1).build()
   }
}
----

Run the application to verify that the job is registered and that it fires every second.

==== Create a stateful job that's a POGO

This is really two steps in one since a job can be stateful or stateless, and a service or defined in `src/main/groovy` as a POGO, but we'll create one job to reduce the overall length of this tutorial.

Run this to create the job:

....
$ grails create-job DarkHelmet --pogo --stateful
....

which will be generated in `src/main/groovy/schwartztest/DarkHelmetJob.groovy` (shown here with comments removed):

[source,groovy]
----
package schwartztest

import com.agileorbit.schwartz.StatefulSchwartzJob
import groovy.transform.CompileStatic
import groovy.util.logging.Slf4j
import org.quartz.JobExecutionContext
import org.quartz.JobExecutionException
import org.springframework.stereotype.Component

@CompileStatic
@Component
@Slf4j
class DarkHelmetJob implements StatefulSchwartzJob {

   void execute(JobExecutionContext context) throws JobExecutionException {
   }

   void buildTriggers() {
   }
}
----

As before, add a trigger in `buildTriggers()` and a println statement in `execute()`

[source,groovy]
----
package schwartztest

import com.agileorbit.schwartz.StatefulSchwartzJob
import groovy.transform.CompileStatic
import groovy.util.logging.Slf4j
import org.quartz.JobExecutionContext
import org.quartz.JobExecutionException
import org.springframework.stereotype.Component

@CompileStatic
@Component
@Slf4j
class DarkHelmetJob implements StatefulSchwartzJob {

   void execute(JobExecutionContext context) throws JobExecutionException {
      println "$context.trigger.key/$context.jobDetail.key at ${new Date()}"
   }

   void buildTriggers() {
      triggers << factory('DarkHelmet_Every2Second').intervalInSeconds(2).build()
   }
}
----

Because this is not a service, it won't be automatically discovered by the plugin and won't be registered in Quartz, but there are a few options. Note that the class is annotated with the Spring {apidocs_spring}org/springframework/stereotype/Component.html[Component] annotation; this is not required and can be removed, but if you've enabled component scanning, e.g. by annotating your `Application` class:

[source,groovy]
----
package schwartztest

import grails.boot.GrailsApp
import grails.boot.config.GrailsAutoConfiguration
import groovy.transform.CompileStatic
import org.springframework.context.annotation.ComponentScan

@CompileStatic
@ComponentScan('schwartztest')
class Application extends GrailsAutoConfiguration {
   static void main(String[] args) {
      GrailsApp.run this, args
   }
}
----

then your job class will be registered as a Spring bean and because it implements `SchwartzJob` it will be auto-registered in Quartz at startup.

If you prefer, you can register the job as a Spring bean in `grails-app/conf/spring/resources.groovy`, e.g.

[source,groovy]
----
import schwartztest.DarkHelmetJob

beans = {
   darkHelmetJob(DarkHelmetJob) {
      quartzService = ref('quartzService')
   }
}
----

==== Create a non-bean job

There's no requirement that jobs be registered as Spring beans, it's just a convenience. You can manage job registration and scheduling entireley yourself if you prefer. Run the `create-job` script again to create a POGO job class:

....
$ grails create-job Barf --pogo
....

and add a println statement in `execute()` but don't create any triggers, and delete the `Component` annotation:

[source,groovy]
----
package schwartztest

import com.agileorbit.schwartz.SchwartzJob
import groovy.transform.CompileStatic
import groovy.util.logging.Slf4j
import org.quartz.JobExecutionContext
import org.quartz.JobExecutionException

@CompileStatic
@Slf4j
class BarfJob implements SchwartzJob {

   void execute(JobExecutionContext context) throws JobExecutionException {
      println "$context.trigger.key/$context.jobDetail.key at ${new Date()}"
   }

   void buildTriggers() {
   }
}
----

Now you have several options. You could manually register the job yourself, e.g. in `BootStrap` (or later at runtime, e.g. in a service):

[source,groovy]
----
import com.agileorbit.schwartz.QuartzService
import org.quartz.SchedulerException
import schwartztest.BarfJob

class BootStrap {

   QuartzService quartzService

   def init = {
      BarfJob job = new BarfJob()
      try {
         quartzService.scheduleJob job
      }
      catch (SchedulerException e) {
         log.error e.message, e
      }
   }
}
----

or you could create a `JobDetail` and optionally some triggers and register the job using those (and you could do the same for other job classes that implement `Job` but not `SchwartzJob`, even Java classes):

[source,groovy]
----
import com.agileorbit.schwartz.QuartzService
import org.quartz.JobDetail
import org.quartz.SchedulerException
import org.quartz.Trigger
import schwartztest.BarfJob

class BootStrap {

   QuartzService quartzService

   def init = {

      BarfJob job = new BarfJob()

      JobDetail jobDetail = job.jobBuilder().build()
      Collection<? extends Trigger> triggers = ...

      try {
         quartzService.scheduleJob jobDetail, triggers, false
      }
      catch (SchedulerException e) {
         log.error e.message, e
      }
   }
}
----

Once the job is registered, you can trigger the job to run immediately whenever you want:

[source,groovy]
----
import com.agileorbit.schwartz.QuartzService
import static org.quartz.JobKey.jobKey

class SomeService {

   QuartzService quartzService

   void someMethod() {
      quartzService.triggerJob jobKey('BarfJob')
   }
}
----

[[jdbcJobStorageTutorial]]
=== JDBC Job Storage Tutorial

There's not much to do to change from in-memory job storage to database storage, but be sure to read the <<jdbcJobStorage>> section of the docs before starting this tutorial.

In this example MySQL is used but you can use any of the database types supported by Quartz. Very few details are database-specific, primarily just the initial database creation steps.

If you don't already have a MySQL database to work with, run these commands in a MySQL client as the root user or another user with permission to create databases and grant permissions:

[source,sql]
----
> create database quartz_jdbc_test;

> grant all on quartz_jdbc_test.* to quartztest@localhost identified by 'quartztest';
----

==== Configure the DataSource

Add a dependency in `build.gradle` for the JDBC driver for your database (be sure to use the latest version available):

[source,groovy]
----
dependencies {
   ...
   runtime 'mysql:mysql-connector-java:5.1.39'
   ...
}
----

and update `application.groovy` (or make the equivalent changes in `application.yml` if you haven't converted it to Groovy syntax yet) to use the correct driver class, dialect, url, username, and password:

[source,groovy]
----
dataSource {
   ...
   dialect = org.hibernate.dialect.MySQL5InnoDBDialect
   driverClassName = 'com.mysql.jdbc.Driver'
   password = 'quartztest'
   url = 'jdbc:mysql://localhost/quartz_jdbc_test'
   username = 'quartztest'
   ...
}
----

==== Create the database tables

You'll need to create the database tables that Quartz uses to store job and trigger information. As described in the <<jdbcJobStorage>> section there are three options, using one of the Quartz scripts from the full distribution, or using one of the plugin commands. Use whichever approach you prefer and apply the changelog or execute the SQL to create the tables.

If you're using the database-migration plugin (or Liquibase directly), you should use the <<create-jdbc-tables-changelog>> command, e.g.

....
$ grails create-jdbc-tables-changelog grails-app/migrations/quartz_jdbc.groovy
....

Add the file to your main changelog file and run

....
$ grails dbm-update
....

The <<create-jdbc-sql>> command is similar but only has a dependency on Hibernate. Run the script to generate the SQL:

....
$ grails create-jdbc-sql quartz_jdbc.sql
....

and use the MySQL client or another tool to run the SQL statements and create the tables.

==== Enable database storage

Once the database tables are available, set the `jdbcStore` config property to `true`:

[source,groovy]
----
quartz {
   jdbcStore = true
}
----

Since MySQL uses the default `DriverDelegate`, it's not required to specify the delegate class name, but if you're using a database that has a custom implementation (e.g. PostgreSQL) then you would also set that, e.g.

[source,groovy]
----
import org.quartz.impl.jdbcjobstore.PostgreSQLDelegate

quartz {
   jdbcStore = true
   properties {
      jobStore {
         driverDelegateClass = PostgreSQLDelegate.name
      }
   }
}
----

NOTE: Imports must be in `grails-app/conf/runtime.groovy` (Grails 3.1.11+)

[[clusterTutorial]]
=== Cluster Tutorial

Be sure to read the <<clustering>> section of the docs before starting this tutorial.

==== Configure database job storage

Database job storage is required before configuring a Quartz cluster, so configure that first using the <<jdbcJobStorageTutorial>> (or by making the required changes in an existing application).

// quartz.properties.scheduler.instanceId='node2'

==== Enable clustering

Next, enable clustering by setting `isClustered` to `true` in the config, and set the `instanceName` property to define the name for the cluster. For now, also set the value for `instanceId` to "`AUTO`" to let Quartz assign a unique value for each server node:

[source,groovy]
----
quartz {
   jdbcStore = true
   properties {
      jobStore {
         isClustered = true
      }
      scheduler {
         instanceId = 'AUTO'
         instanceName = 'ClusterTutorial'
      }
   }
}
----

==== Start the app

Enable logging for the Quartz classes in `logback.groovy`:

[source,groovy]
----
logger 'org.quartz', INFO
----

and start the app and you should see output similar to this:

[source]
----
INFO org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.2.3 created.
INFO org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.2.3) 'ClusterTutorial' with instanceId '...'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.springframework.scheduling.quartz.LocalDataSourceJobStore' - which supports persistence. and is clustered.
INFO org.quartz.core.QuartzScheduler - Scheduler ClusterTutorial_$_... started.
----

==== Create a simple job

Stop the app and create a simple job that we can use to verify that clustering is enabled and working:

....
$ grails create-job ClusterTest
....

[source,groovy]
----
package clustertest

import com.agileorbit.schwartz.SchwartzJob
import grails.gorm.transactions.Transactional
import groovy.transform.CompileStatic
import groovy.util.logging.Slf4j
import org.quartz.JobExecutionContext
import org.quartz.JobExecutionException

@CompileStatic
@Slf4j
class ClusterTestJobService implements SchwartzJob {

   @Transactional
   void execute(JobExecutionContext context) throws JobExecutionException {
      println "$context.trigger.key/$context.jobDetail.key at ${new Date()}"
   }

   void buildTriggers() {
      triggers << factory('ClusterTest_EverySecond').intervalInSeconds(1).build()
   }
}
----

==== Run two instance to check that clustering is configured

Start the app again and verify that the job fires and prints to the console every second:

....
$ grails run-app --port=8081
....

Open a second terminal and run a second instance of the app on another port and verify that the job runs in both instances, but that each time the trigger fires it only executes on one of the running instances:

....
$ grails run-app --port=8082
....

Quartz makes no guarantees about load distribution among cluster nodes and in general will tend to run jobs on the first instance they happen to run on, so you may not see any output in the second window. But if you stop the first server instance (either with a clean shutdown or more forcibly) then you will definitely see that the job starts firing on the second instance, possibly after a delay of a few seconds.

==== Change from automatic instance ids to explicitly set values

Edit `application.groovy` and remove the `instanceId` setting:

[source,groovy]
----
quartz {
   jdbcStore = true
   properties {
      jobStore {
         isClustered = true
      }
      scheduler {
         instanceName = 'ClusterTutorial'
      }
   }
}
----

and add this block to `build.gradle` to enable passing system properties from the commandline:

[source,groovy]
----
configure(bootRun) {
   systemProperties System.properties
}
----

Start the two instances again, but this time passing the cluster node id in addition to the server port:

....
$ grails -Dquartz.properties.scheduler.instanceId=node1 run-app --port=8081
....

and

....
$ grails -Dquartz.properties.scheduler.instanceId=node2 run-app --port=8082
....

and you should see from the logging output that clustering is enabled and that the specified node names are used instead of randomly assigned values, and that the work of running the sample job is split between the two instances.
